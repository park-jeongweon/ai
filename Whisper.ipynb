{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-jeongweon/ai/blob/main/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Whisper 및 필수 패키지 설치 (Colab 셀에서 실행)\n",
        "!pip install -q openai-whisper\n",
        "!apt update && apt install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4WC1Ef4P38E9",
        "outputId": "3c793577-3b6b-4d77-b75a-2f71b6de9bf9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [Connected to r2u.stat.\u001b[0m\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 라이브러리 임포트\n",
        "import whisper\n",
        "from google.colab import files\n",
        "import os"
      ],
      "metadata": {
        "id": "cBdrW8Sy38nV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 오디오 파일 업로드 (직접 파일을 업로드하거나, 업로드하지 않으면 예제 파일을 사용)\n",
        "print(\"오디오 파일을 업로드 해주세요.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    audio_file = list(uploaded.keys())[0]\n",
        "    print(f\"업로드된 파일: {audio_file}\")\n",
        "else:\n",
        "    # 업로드된 파일이 없으면 예제 파일 다운로드\n",
        "    audio_file = \"audio.mp3\"\n",
        "    !wget -q https://cdn.openai.com/whisper/audio.mp3 -O {audio_file}\n",
        "    print(\"예제 파일(audio.mp3)을 다운로드했습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "mVG0p4wI3-Em",
        "outputId": "fe50e9da-39fb-4f94-aac1-076c9ccfeb36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오디오 파일을 업로드 해주세요.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3cc8a00b-27a1-4cd0-8082-2147ac8f6a93\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3cc8a00b-27a1-4cd0-8082-2147ac8f6a93\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 박정원 표준녹음.mp3 to 박정원 표준녹음.mp3\n",
            "업로드된 파일: 박정원 표준녹음.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Whisper 모델 로드 ('base' 모델 사용, \"tiny\", \"small\", \"medium\", \"large\" 선택가능)\n",
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GiJBvOQm4AYM",
        "outputId": "2a7b8cd3-854d-49d4-fcde-76f7dc01f947"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:29<00:00, 51.3MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 음성 파일을 텍스트로 변환 (STT)\n",
        "result = model.transcribe(audio_file)"
      ],
      "metadata": {
        "id": "HsyQKG824BAt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 결과 출력\n",
        "print(\"Transcription:\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4lirpLXO4CSC",
        "outputId": "2fd439c6-d617-4219-fc68-104919d9142f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:\n",
            " 아래는 긍정적인 자기개별과 명상을 주제로 약 1시간 분량의 한글 텍스트 낭송용입니다. 각 파트는 심화된 내용과 다양한 예시로 구성하여 풍부하게 작성했습니다. 1. 하루를 여는 긍정의 힘 여러분 오늘도 새로운 하루를 맞이했습니다. 우리의 하루는 어떤 마음가짐으로 시작하느냐에 따라 크게 달라질 수 있습니다. 긍정의 힘을 믿고 스스로를 향해 따뜻한 말을 걸어봅시다. 나는 오늘의 날을 존중합니다. 작은 성공을 쌓아 큰 목표를 향해 나아갑니다. 아침에 눈을 뜨고 가장 먼저 어떤 생각을 떠올리느냐는 우리의 하루를 바꾸는 열쇠입니다. 긍정적인 다짐은 우리의 뇌를 각성시키고 더 나은 선택을 돕습니다. 2. 나를 알아가는 시간 많은 사람들이 자신에 대해 잘 안다고 생각하지만 사실 우리는 종종 바쁘다는 이유로 스스로를 돌아보지 못합니다. 나는 어떤 사람일까? 나는 무엇을 진정으로 원하는가? 이 질문들은 단순하지만 깊이 있는 성찰로 이끕니다. 때로는 글을 써보며 생각을 정리해보세요. 오늘 내가 느끼는 감정, 나의 소중한 목표를 기록해보세요. 3. 감사의 힘을 되새기기 우리는 때때로 감사해야 할 일들을 당연하게 받아들이곤 합니다. 하지만 작은 순간에도 감사함을 느끼는 마음은 삶을 더 풍요롭게 만듭니다. 오늘의 첫 햇살을 맞이하며 감사하기 나를 도와준 주변 사람들에게 감사하기 내가 이룬 작은 성취에 스스로 감사하기 나는 내 삶의 소중한 것들에 감사드립니다. 이 짧은 문장은 우리의 일상을 따뜻하게 바꿀 수 있습니다. 4. 마음을 다스리는 호흡 호흡은 생명 유지의 기본이지만 때로는 삶을 치유하는 힘이 됩니다. 심호흡을 통해 우리의 몸과 마음을 차분히 가라앉혀봅시다. 천천히 들이쉬며 마음속 불안과 긴장을 떠올려 보세요. 숨을 내쉬며 불안이 몸을 빠져나가며 평온함으로 채워진다고 상상해보세요. 이러한 호흡 연습은 스트레스를 줄이고 집중력을 녹췌이며 마음의 평화를 되찾는 강력한 도구가 됩니다. 5. 도전과 실패를 받아들이기 삶은 도전의 연속입니다. 때로는 실패를 경험할 수도 있습니다. 그러나 실패는 끝이 아니라 더 나은 방향으로 나아가기 위한 과정입니다. 역경을 이겨낸 사람들의 이야기를 떠올려 봅시다. 에디스는 전구 발명 전 수천변의 실패를 겪었습니다. 그는 이렇게 말했습니다. 나는 실패한 것이 아니다. 다만 전구를 만들 수 없는 방법을 발견했을 뿐이다. 실패는 배움의 기회일 뿐입니다. 우리의 성장이 없애세는 안 될 자양분입니다. 6. 나 자신에게 보내는 응원 우리의 모두는 종종 자신에게 너무 엄격해집니다. 그러나 스스로에게 따뜻한 응원의 말을 보내는 것은 용기의 씨앗이 됩니다. 나는 나의 노력을 존중합니다. 실패는 더 나은 내를 위한 디듬톨입니다. 자기 응원은 단순한 위로를 넘어 더 큰 자신감을 불어넣어 줍니다. 이러한 습관은 자신 뿐만 아니라 주변 사람들에게도 긍정적인 영향을 줍니다. 7. 작은 성공을 축하하기 우리는 종종 큰 성취만을 바라보며 작은 성공을 강과하곤 합니다. 하지만 매일의 작은 성공이 쌓일 때 더 큰 꿈을 향해 나아갈 수 있습니다. 오늘의 어제보다 한 걸음 나아갔습니다. 나는 오늘의 하루의 목표를 달성했습니다. 스스로를 격려하는 작은 습관이 점점 더 큰 성취를 이루게 만듭니다. 8. 행동의 중요성 생각만으로는 변화를 만들 수 없습니다. 작은 행동이라도 꾸준히 실탕할 때 변화가 시작됩니다. 새로운 일에 도전해보기, 기존 습관을 개선하기, 하루에 5분이라도 나를 위한 시간을 보내기, 작은 행동은 우리의 삶을 긍정적으로 변화시키는 첫 걸음입니다. 9. 명상으로 마음 다스리기 명상은 우리의 내면을 깨우고 복잡한 생각들을 정리해 줍니다. 편안하게 앉아서 눈을 감고 깊은 숨을 들이쉬어 보세요. 머릿속을 스쳐 지나가는 생각들은 구름처럼 떠올랐다 사라지게 됩니다. 집중할 틈도 없이 억지로 없애려 하지 않아도 괜찮습니다. 그저 나의 호흡과 지금 이 순간에 집중하세요. 10. 자연과의 교감 때로는 자연 속에서 스스로를 돌아보는 시간을 가져보세요. 잔잔한 바람, 새들의 노래, 나뭇잎의 흔들림 소리를 들어보세요. 대자연은 말 없어도 우리에게 유한을 줍니다. 매일 10분이라도 자연을 느낄 수 있는 시간을 가져보세요. 인내심 기르기 인내는 꾸준한 성장을 위한 필수 요소입니다. 어려운 일이 닥칠 때 조급해 하지 말고 천천히 나아가세요. 산을 옮기는 것도 작은 삽질부터 시작된다는 말처럼 매일의 작은 노력이 쌓여 큰 성치를 이룹니다. 12. 내일을 위한 다짐 이제 오늘의 마지막 순간을 정리해 봅시다. 스스로를 응원하고 오늘의 성치를 돌아보며 내일을 계획해 보세요. 나는 내일도 최선을 다할 것입니다. 새로운 기회가 찾아오기를 기대합니다. 우리는 충분히 자라고 있습니다. 나 자신을 믿고 걸어가면 우리는 성장할 것입니다. 마무리 인사 긴 여정을 함께 해 주셔서 감사합니다. 여러분의 하루가 행복과 성취로 가득 차길 바랍니다. 이 텍스트는 약 1시간 분량으로 작성되었습니다. 낭속의 속도에 따라 분량의 필요에 따라 조정해 주세요. 나의 말, 분량을 4배로 다시 작성해 주시기 바랍니다. 하루를 여는 긍정적인 첫 걸음 우리는 여러분 우리의 새로운 하루를 맞이했습니다. 이 하루는 누구 행위라 공편하게 이루어지는 선물입니다. 어떤 일이 있는지 긍정의 힘으로 이 하루를 시작해 봅시다. 아침에 눈을 뜨고 이렇게 스스로에게 말해 봅시다. 오늘 하루도 소중한 기회다. 나는 새로운 기회를 향해 나아간다. 오늘 나는 성장한다. 어제의 실수와 오늘의 후회는 지나갔습니다. 오늘이라도 새로운 기회가 우리 눈앞에 펼쳐져 있습니다. 11. 인내심과 끔기 기르기 인내심은 삶에서 큰 힘을 줍니다. 당장의 결과를 보지 못하더라도 꾸준히 나아가는 자세는 결국 결실을 맺습니다. 산을 옮기는 것도 작은 삽질부터 시작된다. 매일의 작은 노력이 모여 큰 성취를 이루어냅니다. 12. 자연 속에서 자신을 돌아보기 자연은 우리에게 끝없는 치유와 위로를 줍니다. 숲 속의 바람, 우리의 흘러가는 물소리, 산들의 아름다운 모습, 떨어지는 단풍잎, 흘러가는 바람소리와 물소리, 잔잔한 파도의 소리를 떠올려 보세요. 자연 속에서 우리는 스스로를 돌아보고 삶의 작은 소중함을 느낄 수 있습니다. 13. 컴퓨터 공부하기 컴퓨터는 우리에게 있어서 가장 필수적인 요소가 될 수 있습니다. 컴퓨터가 없는 삶은 우리는 상상할 수 없습니다. 컴퓨터가 우리에게 스트레스를 줄 수 있지만, 컴퓨터는 끊임없이 우리에게 인사이트를 주고 업무의 효율성과 시간 관리의 효율성을 동시에 부여합니다. 이러한 컴퓨터를 생활과 교육과 연구에 활용하는 순간 우리는 또 다른 세계에 접근할 수 있습니다. 또 하나 배워야 될 점은 AI입니다. 즉 인공지능이라고 할 수 있습니다. 인공지능은 이제 없어서는 안 될 생활의 필수품으로 등장하고 있습니다. 인공지능을 통해서 우리가 삶의 효율성과 삶의 시간을 확보할 수 있는 대안으로 활용할 수 있습니다. 우리는 인공지능이 인간을 지배하는 툴이 아니라 인공지능을 통해서 인간이 삶의 풍요로무를 확보할 수 있다고 믿어야 됩니다. 인공지능의 학습은 첫 걸음부터 쉬운 툴을 학습하는 것으로 시작해야 됩니다. 인공지능이 가지고 있는 광대한 가능성을 보면서 우리는 우리들의 삶의 시간 확보와 행복과 풍요로움을 동시에 가질 수 있어야 됩니다. 인공지능은 이제 선택이 아닌 필수 요소로 자리 잡고 있습니다. 우리는 또한 내일을 위한 다짐을 해야 됩니다. 마지막으로 내일을 위해 다짐해봅시다. 나는 내일도 최선을 다할 것이다. 새로운 기회를 향해 나아갈 것이다. 우리는 자리 잡고 앞으로 자랄 것입니다. 긍정적인 마음과 희망을 안고 내일을 향해 힘차게 출발해야 됩니다. 이러한 하루에 대한 반성과 내일에 대한 기획이 우리의 인생을 풍요롭게 할 수 있습니다. 또 한 가지 음악 감상을 들 수 있습니다. 자율 갖추어진 데스크 탑에서 데스크 파일을 이용해서 본인이 좋아하는 음악을 감상하고 본인의 감정과 영혼을 순화할 수 있는 시간을 확보하셔야 됩니다. 이를 통해서 저희들의 감성은 더욱더 풍요로워지고 상상력은 발전할 수 있을 것입니다. 또한 끊임없는 독서의 중요성들도 여러분들이 알으셔야 됩니다. 독서는 자기를 만들어가는 부분입니다. 독서를 통해서 자기 시야의 제한을 없애고 광활한 세계와의 만남을 시도하시기 바랍니다. 긴 여정을 함께해 주셔서 감사합니다. 여러분들의 하루가 행복과 성취로 가득차기를 바랍니다. 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 텍스트 결과를 파일로 저장\n",
        "transcript_file = \"transcription.txt\"\n",
        "with open(transcript_file, \"w\") as f:\n",
        "    f.write(result[\"text\"])"
      ],
      "metadata": {
        "id": "uv_4nNiS47Va"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. 텍스트를 마침표(.) 단위로 분리하여 각 행에 한 문장씩 저장\n",
        "#    (문장 끝에 마침표를 붙여서 저장합니다.)\n",
        "lines_file = \"transcription_lines.txt\"\n",
        "# 텍스트를 마침표 단위로 분리한 후 앞뒤 공백 제거 및 빈 문자열 제거\n",
        "sentences = [s.strip() for s in result[\"text\"].split('.') if s.strip()]\n",
        "with open(lines_file, \"w\") as f:\n",
        "    for sentence in sentences:\n",
        "        f.write(sentence + \".\\n\")\n",
        "print(\"마침표 단위로 분리된 텍스트 파일을 생성했습니다:\", lines_file)\n",
        "files.download(lines_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Et5wPk3e8jnx",
        "outputId": "3f9ebaef-467a-49ff-bdd2-645637742a6b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마침표 단위로 분리된 텍스트 파일을 생성했습니다: transcription_lines.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f89f7399-0636-4bad-a1c9-71d4603dc14c\", \"transcription_lines.txt\", 9926)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}